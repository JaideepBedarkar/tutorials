{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nIntroduction to the Hybrid Frontend\n===================================\n**Author:** `Matthew Inkawhich <https://github.com/MatthewInkawhich>`_\n\nIn this tutorial, we will experiment with some of the key features of\nthe PyTorch hybrid frontend.\n\nThis flexible programming model enables the co-existance and seamless\ninteraction between an imperative eager interface designed for\nexperimentation and easy debugging, and a declarative graph mode in\nwhich models can be optimized for performance and exported to\nlarge-scale production environments.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eager Mode\n----------\n\nPyTorch's eager mode is the familiar PyTorch interface. Eager mode is\neasy because it is simply idiomatic Python. Because of the imperative\nnature of the mode, we can use our favorite Python debugging tools such\nas ``pdb`` and ``print`` statements. This mode is designed for rapid\nmodel prototyping and ambitious research efforts.\n\nHowever, it is difficult to optimize models represented in eager mode\nfor large-scale production and deployment.\n\nGraph Mode\n----------\n\nThe graph mode creates a deferred model representation, which is a\ncommon methodology in many deep learning frameworks. In graph mode, you\nwrite a model definition in Python, which is run later on in the Caffe2\nC++ runtime environment. Having a deferred representation has numerous\nbenefits, including:\n\n  - *Model simplicity*: Model representation is simpler and more restricted\n  - *Optimization*: We can apply various optimization techniques to create\n    more efficient deployable models\n  - *Improved performance*: We can leverage parallel and out-of-order\n    execution, and target highly optimized hardware architectures\n  - *Easy export*: Exporting a serialized model is a breeze with ONNX\n\n.. figure:: /_static/img/hybrid_frontend/pytorch_workflow_small.jpg\n   :alt: workflow\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "JIT Compiler\n------------\n\nTo accomodate to as many workflows as possible, PyTorch not only\nprovides both an eager mode and a graph mode, but a transition mechanism\nbetween them: ``torch.jit``. This enables the use of the newest\nstate-of-the-art models from research environments to be deployed and\nexported in demanding production environments without massive code\nre-writes.\n\nTo learn more see `this\nletter <https://pytorch.org/2018/05/02/road-to-1.0.html>`__ from the\nPyTorch team.\n\nThere are two separate modes for performing this transition.\n\nTracing Mode\n~~~~~~~~~~~~\n\nTracing mode is a non-invasive tool which traces your Python module or\nfunction to create an internal representation that is compiled to graph\nmode. The ``torch.jit.trace`` function takes your module or function and\nan example data input, and traces the computational steps that the data\nencounters as it progresses through the model.\n\nAn advantage of this approach is that it is an unobtrusive process that\nwill work regardless of how your Python code is structured. However,\nbecause of the way the tracer works, data-dependent control flows (if\nstatements, loops) cannot be fully captured. Rather, only the control\nsequence traced using the example input will be recorded.\n\nScript Mode\n~~~~~~~~~~~\n\nTo compile models with data-dependent control flow elements, such as\nRNNs, we simply add a ``@torch.jit.script`` decorator to our function.\nThis annotation lets PyTorch know that the function may contain\ndata-dependent control flows. Now, our loops, conditionals, and\niterative data mutations are handled explicitly.\n\nThe one constraint for users compiling with script mode is that it\ncurrently only supports a restricted subset of Python. As of now,\nfeatures such as generators, defs, and Python data structures are not\nsupported. To remedy this, you can invoke traced modules from script\nmodules (and vice-versa), and you can call pure Python functions and\nmodules from script modules. However, the operations done in the pure\nPython functions will not be compiled, and will run as-is.\n\nRegardless of which compilation mode you need, the end result is a\nPython-free model representation which can be optimized and exported.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "k-Nearest Neighbors Example\n---------------------------\n\nTo showcase the basics of the hybrid frontend, we will implement a basic\nclassification algorithm using a mix of both compilation modes and raw\nPython.\n\nDataset\n~~~~~~~\n\nWe will use the famous `Iris\ndataset <https://archive.ics.uci.edu/ml/datasets/iris>`__ as our toy\nproblem.\n\n-  3 classes of flowers (Iris Setosa, Iris Versicolour, Iris Virginica)\n-  150 total samples (50 of each class)\n-  4 features (Sepal length, Sepal width, Petal length, Petal width)\n\n.. figure:: /_static/img/hybrid_frontend/iris_pic.jpg\n   :alt: iris\n\nAlgorithm\n~~~~~~~~~\n\nk-Nearest Neighbors is a relatively simple classification algorithm. It\nis instance-based and lazy, meaning that it uses all training examples\nto model the training data, and delays all computation (model fitting)\nuntil inference time.\n\n.. figure:: /_static/img/hybrid_frontend/220px-KnnClassification.png\n   :alt: knn\n\n   k-NN visualization\n\nThe idea is to find the **k** closest training samples to a given test\ninstance, and predict the class that has the highest representation in\nthis group.\n\nFor example, if k=3, and the k closest training samples are class {2, 1,\n2}, the prediction for the test instance is 2. In the event of a voting\ndraw, we reduce k and vote again.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On to the Code!\n---------------\n\nEnough talking, let's get to the code!\n\nWe'll start by importing some necessities.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport torch\nfrom torch.jit import script, trace\nimport csv\nimport random\nimport operator\nimport collections\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle data\n~~~~~~~~~~~\n\nThe next step is to download the Iris dataset into ``data/iris.data``.\nTo get an idea of what the file looks like, we'll print a few lines.\n\n.. Note ::\n   Download the data from\n   `here <https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data>`_\n   and extract it in a ``data`` directory under the current directory.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filename = \"data/iris.data\"\n\n# Print 10 random lines\ntry:\n    datafile = open(filename, 'r')\nexcept IOError:\n    print(\"Cannot open data file: {}. Have you downloaded it yet?\".format(filename))\n    exit()\nlines = datafile.readlines()\n# Last line in file is empty, we'll deal with this later\nlines = lines[:-1]\nrandom.shuffle(lines)\nfor line in lines[:10]:\n    print(line.strip())\ndatafile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll create our dataset, which is a list of lists containing each\nrow of the data file (shape=(150,5)).\n\nIn the next step, we will convert this to a torch tensor, so we have to\nconvert the string flower species names to float type so that the types\nof all elements are the same. To do this, we define a simple mapping in\nthe ``class_labels`` dictionary.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Declare mapping between string class labels and a numeric representation\nclass_labels = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n\n# Takes a filename with comma separated contents, returns dataset list\ndef create_dataset(filepath):\n    with open(filepath, 'r') as datafile:\n        # Create dataset list\n        lines = csv.reader(datafile)\n        dataset = list(lines)\n        # Remove empty lines\n        dataset = [x for x in dataset if x]\n        # Convert string label to numeric label\n        for row in dataset:\n            for i in range(4):\n                row[i] = float(row[i])\n            row[4] = float(class_labels[row[4]])\n        return dataset\n\n\n# Load dataset\ndataset = create_dataset(\"data/iris.data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will declare our ``train_ratio`` and split the dataset. Notice\nthat we cast the ``train_set`` and ``test_set`` splits to *torch.tensor*\nbefore returning.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Ratio of samples used for training\ntrain_ratio = .70\n\n# Takes dataset list and a train percent value for splitting data\ndef split_dataset(dataset, train_ratio):\n    # Shuffle data\n    random.shuffle(dataset)\n    # Calculate number of files in train and test set\n    train_len = int(len(dataset) * train_ratio)\n    test_len = int(len(dataset) - train_len)\n    # Split train and test sets\n    train_set = dataset[:train_len]\n    test_set = dataset[-test_len:]\n    # Convert splits to torch tensor and return\n    return torch.tensor(train_set), torch.tensor(test_set)\n\n\n# Split dataset\ntrain_set, test_set = split_dataset(dataset, train_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement k-NN functions\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe next step is to implement the helper functions that we will use to\ncarry out the k-NN algorithm. Because we use torch tensors to operate\non, we can use the PyTorch JIT compiler to compile our functions to a\ngraph representation.\n\ngetDistance\n^^^^^^^^^^^\n\nThe first function that we'll implement is ``getDistance``, which is how\nwe will calculate the distance between a ``test_instance`` and a\n``train_instance``. Because our features are all real numbers, we will\nuse Euclidean distance:\n\n\\begin{align}distance = \\sqrt{(train[0] - test[0])^2 + (train[1] - test[1])^2 + \\ldots +  (train[n] - test[n])^2}\\end{align}\n\n--------------\n\n**Trace mode**\n\nBecause this function involves sequential torch tensor operations, with\nno data-dependent control flows, we can use the **trace** function to\ncompile it to a graph representation.\n\nNotice that to trace a function, you must first declare the traced\nversion of the function (``getDistance_traced``) using the\n``torch.jit.trace`` function. Notice that the ``trace`` function is a\n`Curried function <https://en.wikipedia.org/wiki/Currying>`__. For us\nthis means that calling it requires two arguments, each surrounded by\nits own set of parenthesis. In the example below, we show that the\noutputs of the non-compiled and compiled functions are identical, and\nuse the ``.graph`` attribute to show the graph in a human readable\nformat.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Takes a train_instance and test_instance, and returns a scalar torch\n#  tensor containing the distance value\ndef getDistance(train_instance, test_instance):\n    # Element wise subtraction; disregard last element (class)\n    #diff = torch.sub(train_instance[:4], test_instance[:4])\n    diff = train_instance[:4] - test_instance[:4]\n    # Square each element of the distance tensor\n    #sqrs = torch.pow(diff, torch.tensor(2.0))\n    sqrs = diff ** torch.tensor(2.0)\n    # Sum all elements in sqrs tensor\n    sumsqrs = torch.sum(sqrs)\n    # Take square root of sumsqrs to obtain distance\n    distance = torch.sqrt(sumsqrs)\n    return distance\n\n\n########## Example ##########\n# Non-compiled\nprint(\"Euclidean distance between train_set[0] and train_set[1]:\")\nprint(\"train_set[0]:\", train_set[0])\nprint(\"train_set[1]:\", train_set[1])\ndistance = getDistance(train_set[0], train_set[1])\nprint(\"Non-compiled output:\", distance)\n\n# Compiled\ngetDistance_traced = trace(train_set[0], train_set[1])(getDistance)\ndistance_traced = getDistance_traced(train_set[0], train_set[1])\nprint(\"Compiled output:\", distance_traced)\nprint(\"getDistance_traced.graph:\", getDistance_traced.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "getSortedLabels\n^^^^^^^^^^^^^^^\n\nThe ``getSortedLabels`` function takes two parallel tensors\n(``distances`` & ``labels``) of length *train\\_instances* which contain\nthe distances between train instances and a given test instance, and the\ncorresponding class labels. The ``distances`` are sorted first, and we\nreorder the ``labels`` tensor according to the index changes.\n\n--------------\n\n**Trace mode**\n\nOnce again, since this function is simply made up of sequential torch\noperations, we can use **trace** to compile it. Notice that we must use\na scalar tensor for ``k``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Takes parallel distances and labels tensors and returns the sorted labels\ndef getSortedLabels(distances, labels, k):\n    # Sort distances\n    sorted_dists, indices = torch.sort(distances)\n    # Reorder labels according to sorted indices\n    sorted_labels = torch.gather(labels, 0, indices)\n    # Return top-k sorted_labels\n    return sorted_labels[:k]\n\n\n########## Example ##########\n# Non-compiled\nprint(\"Sorted labels example:\")\nds = torch.tensor([6, 8, 3, 5, 9])\nls = torch.tensor([0, 0, 2, 1, 2])\nk = torch.tensor(3)\nsorted_labels = getSortedLabels(ds, ls, k)\nprint(\"Non-compiled output:\", sorted_labels)\n\n# Compiled\ngetSortedLabels_traced = trace(ds, ls, k)(getSortedLabels)\nsorted_labels_traced = getSortedLabels_traced(ds, ls, k)\nprint(\"Compiled output:\", sorted_labels_traced)\nprint(\"getSortedLabels_traced.graph:\", getSortedLabels_traced.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "getNeighbors\n^^^^^^^^^^^^\n\nThe ``getNeighbors`` function takes a ``train_set``, a\n``test_instance``, an empty ``distances`` tensor, an empty ``labels``\ntensor, and a ``k`` value. The ``distances`` and ``labels`` tensors must\nhave same length as ``train_set``. It returns a list of the sorted\n*k-nearest* neighbors (as class labels) to the ``test_instance``. It\ndoes this by iterating over every instance in the ``train_set``,\nrecording the distance between the train instance and the\n``test_instance``, and using our ``getSortedLabels`` function to sort\nthe corresbonding labels based on these distances.\n\n--------------\n\n**Script mode**\n\nNotice that this function contains a data-dependent control flow (our\n*for* loop depends on the data size). Because of this, we must compile\nwith **script** mode. We indicate the use of this mode by adding a\n``@script`` decorator. Note that we can call our traced\n``getDistance_traced``, and ``getSortedLabels_traced`` functions from\nour script function.\n\nFinally, you may be wondering why we use the ``addEntries`` function to\nadd to our ``distances`` and ``labels`` tensors instead of simply:\n\n::\n\n    distances[i] = dist\n    labels[i] = label\n\n\nRemember that only a subset of Python is supported in **script** mode.\nOne requirement is that the only expressions allowed on the left side of\nan assignment operator (=) are variable names and starred expressions.\nSo, one way to circumvent this is to implement pure Python helper\nfunctions such as ``addEntries``.\n\nAlso, notice in the graph output that the loop is captured\n(``prim::Loop``). The **script** mode enables us to convert the Python\nAST directly to graph mode, rather than tracing an example input through\nthe control flow and simply capturing the unrolled loop.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Add elements to distances and labels tensors at index i\ndef addEntries(i, d, l, distances, labels):\n    distances[i] = torch.tensor(d)\n    labels[i] = torch.tensor(l)\n    return distances, labels\n\n# Returns k-nearest neighbors of a train_set to a test_instance\n@script\ndef getNeighbors(train_set, test_instance, distances, labels, k):\n    # Data-dependent control flow\n    for i in range(train_set.size(0)):\n        train_instance = train_set[i]\n        # Calculate Euclidean distance using traced function\n        dist = getDistance_traced(train_instance, test_instance)\n        # Extract label\n        label = train_instance[-1]\n        # Call Python function to add entries at index i\n        distances, labels = addEntries(i, dist, label, distances, labels)\n    # Call traced function to return a labels tensor sorted by distance to the test_instance\n    sorted_labels = getSortedLabels_traced(distances, labels, k)\n    # Take top k\n    neighbors = sorted_labels[:k]\n    return neighbors\n\n\n########## Example ##########\nprint(\"getNeighbors example:\")\nsmall_train_set = train_set[:10]\nk = torch.tensor(3)\ndistances = torch.empty([small_train_set.size(0)])\nlabels = torch.empty([small_train_set.size(0)])\nneighbors = getNeighbors(small_train_set, train_set[10], distances, labels, k)\nprint(\"output:\", neighbors)\nprint(\"getNeighbors.graph:\", getNeighbors.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "getPrediction\n^^^^^^^^^^^^^\n\nOur final function takes the top k neighbors tensor and returns a final\nprediction. The class that has the most representation in the neighbors\ntensor is the one chosen for the final classification. In the case of a\ndraw, the element with the lowest index (the closest neighbor) is\nchosen.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Pure python\ndef getPrediction(neighbors):\n    neighbors = neighbors.numpy()\n    return float(max(neighbors, key=collections.Counter(neighbors).get))\n\n\n########## Example ##########\nprint(\"getPrediction example:\")\nn1 = torch.tensor([2.0, 1.0, 2.0])\nn2 = torch.tensor([1.0, 2.0, 0.0])\nn3 = torch.tensor([0.0, 1.0, 1.0])\nprint(\"n1:\", n1, \"\\tpred:\", getPrediction(n1))\nprint(\"n2:\", n2, \"\\tpred:\", getPrediction(n2))\nprint(\"n3:\", n3, \"\\tpred:\", getPrediction(n3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Testing\n~~~~~~~~~~~\n\nNow it is time to use our functions to test the algorithm on our test\nsplit!\n\nWith the default values of ``k`` = 3 and ``train_ratio`` = .70, you can\nexpect an accuracy in the mid to high 90s. Not bad for an algorithm this\nsimple!\n\nFeel free to tinker with these parameters and see how the results\nchange.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize k\nk = torch.tensor(3)\n\n# Initialize counts for accuracy\ntotal_count = 0\ncorrect_count = 0\n\n# Iterate over every instance in the test_set\nfor test_instance in test_set:\n    total_count += 1\n    # Record ground truth label\n    label = float(test_instance[-1])\n\n    # Initialize distances and labels parallel tensors\n    distances = torch.empty([train_set.size(0)])\n    labels = torch.empty([train_set.size(0)])\n    # Get neighbors\n    neighbors = getNeighbors(train_set, test_instance, distances, labels, k)\n    # Obtain final prediction\n    pred = getPrediction(neighbors)\n    # Check if the prediction matches the ground truth label\n    if label == pred:\n        correct_count += 1\n\nprint(\"Accuracy: {}/{} = {:.2f}%\".format(correct_count, total_count, (correct_count/total_count)*100.0))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}